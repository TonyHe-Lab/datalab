# Story 2.3 - Cost Monitoring Deployment Guide

## Overview
This document provides deployment instructions for the AI cost monitoring system implemented in Story 2.3. The system includes Prometheus metrics export, Alertmanager alert rules, and Grafana dashboard configuration.

## Components

### 1. Prometheus Metrics Exporter
**Location**: `src/ai/prometheus_monitor.py`

**Features**:
- Cost tracking metrics (`ai_cost_total`, `ai_cost_current`)
- Token usage metrics (`ai_tokens_total`, `ai_tokens_current`)
- Request metrics (`ai_requests_total`, `ai_request_duration_seconds`)
- Error metrics (`ai_errors_total`)
- Rate limit metrics (`ai_rate_limit_hits_total`)

**Usage**:
```python
from src.ai.prometheus_monitor import get_monitor

monitor = get_monitor()
monitor.record_cost(10.5, "chat_completion")
monitor.record_tokens(1500, "prompt")
monitor.record_request("chat", "success", 1.5)
monitor.record_error("rate_limit", "chat")
monitor.record_rate_limit("chat")
```

### 2. HTTP Metrics Server
**Starting the server**:
```python
from src.ai.prometheus_monitor import get_monitor

monitor = get_monitor()
monitor.start_http_server(port=8000)  # Default port 8000
```

**Metrics endpoint**: `http://localhost:8000/metrics`

### 3. Alertmanager Rules
**Location**: `config/prometheus/alertmanager-rules.yml`

**Alerts configured**:
1. **HighAICost**: Triggered when AI cost exceeds 10 USD for chat/embedding operations
2. **RateLimitHit**: Triggered when rate limit hits are detected
3. **HighErrorRate**: Triggered when error rate exceeds 10%
4. **HighTokenUsage**: Triggered when token usage exceeds 10,000
5. **ServiceUnavailable**: Triggered when AI service is down

### 4. Grafana Dashboard
**Location**: `config/grafana/ai-cost-dashboard.json`

**Panels included**:
- Total Cost Over Time
- Cost by Operation Type (pie chart)
- Token Usage (prompt, completion, embedding)
- Request Rate
- Error Rate
- Rate Limit Hits

## Deployment Steps

### Option A: With Prometheus Stack (Recommended for Production)

1. **Install Prometheus client**:
```bash
pip install prometheus-client
```

2. **Configure Prometheus**:
```yaml
# prometheus.yml
scrape_configs:
  - job_name: 'ai-service'
    static_configs:
      - targets: ['localhost:8000']
    scrape_interval: 15s
```

3. **Configure Alertmanager**:
```yaml
# alertmanager.yml
route:
  group_by: ['alertname', 'severity']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'web.hook'
receivers:
  - name: 'web.hook'
    webhook_configs:
      - url: 'http://127.0.0.1:5001/'
```

4. **Import Grafana dashboard**:
   - Navigate to Grafana → Dashboards → Import
   - Upload `config/grafana/ai-cost-dashboard.json`

### Option B: Log-based Monitoring (Fallback)

If Prometheus is not available, the system falls back to log-based monitoring:

1. **Cost alerts via logging**:
```python
from src.ai.cost_tracker import CostTracker, Pricing

pricing = Pricing(
    prompt_per_1k=0.01,
    completion_per_1k=0.03,
    embedding_per_1k=0.0001
)
tracker = CostTracker(pricing, alert_threshold=10.0)

# Alerts are logged at WARNING level when threshold is exceeded
```

2. **Monitor logs for alerts**:
```bash
# Monitor cost alerts
tail -f /var/log/ai-service.log | grep "High usage alert"

# Monitor error logs
tail -f /var/log/ai-service.log | grep "ERROR\|WARNING"
```

## Testing

### Unit Tests
```bash
python3 -m pytest tests/ai/test_prometheus_monitor.py -v
python3 -m pytest tests/ai/test_cost_tracker.py -v
```

### Integration Tests
```bash
python3 -m pytest tests/integration/test_cost_rate_monitoring.py -v
```

### Manual Testing
1. Start the metrics server:
```python
python3 -c "from src.ai.prometheus_monitor import get_monitor; m = get_monitor(); m.start_http_server(8000)"
```

2. Generate some metrics:
```python
python3 -c "
from src.ai.prometheus_monitor import record_cost, record_tokens, record_request
record_cost(5.0, 'test')
record_tokens(1000, 'prompt')
record_request('test', 'success', 0.5)
"
```

3. Verify metrics endpoint:
```bash
curl http://localhost:8000/metrics | grep ai_
```

## Monitoring and Maintenance

### Key Metrics to Monitor
1. **Cost trends**: Watch for unexpected cost spikes
2. **Error rates**: Investigate if error rate exceeds 5%
3. **Rate limits**: Monitor for frequent rate limit hits
4. **Token usage**: Track token consumption patterns

### Alert Response Procedures
1. **HighAICost**: Review recent operations, check for anomalies
2. **RateLimitHit**: Implement backoff or request batching
3. **HighErrorRate**: Check Azure OpenAI service status, review error logs
4. **ServiceUnavailable**: Check network connectivity and service health

### Performance Considerations
- Metrics collection adds minimal overhead (<1ms per operation)
- HTTP server uses minimal resources (~10MB RAM)
- Consider increasing scrape interval to 30s for high-volume services

## Troubleshooting

### Common Issues

1. **Prometheus client not installed**:
   ```
   WARNING: Prometheus client not available. Using dummy metrics.
   ```
   **Solution**: Install with `pip install prometheus-client`

2. **Metrics not appearing in Prometheus**:
   **Solution**: Check Prometheus configuration and network connectivity

3. **High memory usage**:
   **Solution**: Reduce metrics retention or increase scrape interval

4. **Alertmanager not firing alerts**:
   **Solution**: Verify Alertmanager configuration and rule syntax

### Log Locations
- Application logs: `/var/log/ai-service.log`
- Prometheus logs: `/var/log/prometheus.log`
- Alertmanager logs: `/var/log/alertmanager.log`

## References
- [Prometheus Documentation](https://prometheus.io/docs/)
- [Alertmanager Documentation](https://prometheus.io/docs/alerting/latest/alertmanager/)
- [Grafana Documentation](https://grafana.com/docs/)
- [Azure OpenAI Pricing](https://azure.microsoft.com/en-us/pricing/details/cognitive-services/openai-service/)
