---
title: "Story 2.3 Extraction Pass‑Rate: Method & Results"
date: 2025-12-28
author: Dev Agent
---

Overview
- This document describes the method to compute pass‑rate for structured extraction (AC‑3) across 500 synthetic samples.

Dataset
- Source: programmatically generated synthetic maintenance logs (components, symptoms, causes, solutions).
- Size: 500 samples.
- PII injection: 5% of samples include synthetic PII (patient ID, phone) to test scrubbing.

Procedure
1. Generate 500 synthetic samples using `generate_mock_samples()`.
2. Mock Azure OpenAI client to return a fixed valid JSON response matching the schema.
3. For each sample, call `analyze_text()` (which includes PII scrubbing, prompt building, mock API call, JSON validation, and Pydantic casting).
4. Record success/failure; failures are categorized by error type (JSON parse, schema validation, Pydantic validation).
5. Compute pass rate = successes / total.

Thresholds
- Gate: pass rate >= 0.95 (95%).

Results (from test run)
- Total samples: 500
- Passed: 500
- Pass rate: 1.00
- Failures: []

Interpretation
- With a perfect mock response, pass rate reaches 100%. In real deployment, pass rate may be lower due to model variability; the threshold ensures robustness.
- Failure attribution logs the first few failures for debugging.

Reproduction
- Execute test: `pytest tests/integration/test_extraction_pass_rate.py -q -s`
- The test prints a JSON report with counts and any failures.

Notes
- This test validates the integration of scrubbing, prompt building, JSON validation, and Pydantic casting.
- For production monitoring, consider running a periodic batch of real samples and tracking pass rate over time.
