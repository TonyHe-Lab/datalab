---
title: "Story 1.3: Database Schema & Extension Validation (Ensure vector extension exists)"
epic: 1
story: 3
status: Ready for Done
---

## Story

**As a** backend developer,
**I want** the Postgres schema created and validated (including vector extension and required tables/indexes),
**so that** the application can store raw logs, structured AI-extracted data, and semantic embeddings required for hybrid search.

## Acceptance Criteria

1. Required Postgres extensions (e.g., vector) are present or created if permitted.
2. Tables `notification_text`, `ai_extracted_data`, and `semantic_embeddings` exist with expected columns and constraints.
3. Indexes for efficient text search and vector similarity (HNSW if available) are created and verified.
4. A migration or SQL script `db/init_schema.sql` is provided to create/validate schema idempotently.
5. A small verification script `dev/verify_db_schema.py` confirms table existence, extension availability, and basic insert/query operations.

## Dev Notes

Data Model Summary:
- `notification_text`: notification_id PK, noti_date, noti_text, noti_issue_type, etc. [Source: docs/prd_shards/10-data-model.md]
- `ai_extracted_data`: notification_id FK, keywords_ai, primary_symptom_ai, root_cause_ai, etc. [Source: docs/prd_shards/10-data-model.md]
- `semantic_embeddings`: notification_id FK, source_text_ai, vector (e.g., 1536 dim), compatible with HNSW index. [Source: docs/prd_shards/10-data-model.md]

Architecture Guidance:
- If vector extension (pgvector) is used, ensure extension installed and the `vector` column uses appropriate dimension (e.g., 1536) matching embedding model. [Source: docs/prd_shards/09-technical-implementations.md]
- Provide fallback guidance if vector extension not available: store embeddings as bytea or JSON and log limitation in story. [Source: docs/prd_shards/10-data-model.md]

WSL/Host Connectivity Note:
- Verification scripts should honor DB_HOST resolution strategy used in the project (see `/etc/resolv.conf` parsing guidance). [Source: docs/prd_shards/09-technical-implementations.md]

Security:
- Migrations must not hardcode credentials. Use env-based connection strings and document required privileges to create extensions and schemas. [Source: docs/prd_shards/12-security.md]

## Tasks / Subtasks
 
- [x] Task 1 (AC: 4) — Add migration SQL
  - [x] Create `db/init_schema.sql` that creates extensions conditionally (e.g., `CREATE EXTENSION IF NOT EXISTS vector;`) and creates tables with IF NOT EXISTS.
  - [x] Add comments explaining each table/column and expected types.

Suggested `db/init_schema.sql` snippets (include these examples in the story for developer copy-paste):

```sql
-- Create extension if allowed (requires superuser)
CREATE EXTENSION IF NOT EXISTS vector;

-- notification_text (通知工单主表)
CREATE TABLE IF NOT EXISTS notification_text (
  notification_id TEXT PRIMARY KEY,
  noti_date TIMESTAMP WITH TIME ZONE NOT NULL,
  noti_text TEXT NOT NULL,
  noti_issue_type TEXT,
  sys_eq_id TEXT,
  created_at TIMESTAMP WITH TIME ZONE DEFAULT now(),
  updated_at TIMESTAMP WITH TIME ZONE DEFAULT now()
);

-- ai_extracted_data (AI提取数据表)
CREATE TABLE IF NOT EXISTS ai_extracted_data (
  id SERIAL PRIMARY KEY,
  notification_id TEXT NOT NULL REFERENCES notification_text(notification_id) ON DELETE CASCADE,
  keywords_ai TEXT,
  primary_symptom_ai TEXT,
  root_cause_ai TEXT,
  summary_ai TEXT,
  solution_ai TEXT,
  confidence_score_ai DECIMAL(5,4),
  extracted_at TIMESTAMP WITH TIME ZONE DEFAULT now()
);

-- semantic_embeddings (向量索引表，使用pgvector)
CREATE TABLE IF NOT EXISTS semantic_embeddings (
  notification_id TEXT NOT NULL REFERENCES notification_text(notification_id) ON DELETE CASCADE,
  source_text_ai TEXT,
  vector vector(1536),
  created_at TIMESTAMP WITH TIME ZONE DEFAULT now(),
  PRIMARY KEY (notification_id)
);

-- Example index (ivfflat) — adjust depending on extension capabilities
CREATE INDEX IF NOT EXISTS semantic_embeddings_vector_idx ON semantic_embeddings USING ivfflat (vector) WITH (lists = 100);
```

Suggested `dev/verify_db_schema.py` minimal implementation:

```python
import os
import sys
import psycopg2

DATABASE_URL = os.getenv('DATABASE_URL') or os.getenv('POSTGRES_URL')
if not DATABASE_URL:
    print('DATABASE_URL not set')
    sys.exit(2)

conn = psycopg2.connect(DATABASE_URL)
cur = conn.cursor()
cur.execute("SELECT to_regclass('public.notification_text')")
print('notification_text exists:', cur.fetchone())
cur.execute("SELECT exists(SELECT 1 FROM pg_extension WHERE extname='vector')")
print('vector extension present:', cur.fetchone())
conn.close()
print('verify_db_schema completed')
```


 - [x] Task 2 (AC: 1,3) — Validate vector extension & indexes
  - [x] Add SQL statements to check extension existence and create HNSW/GIST indexes where supported (e.g., `CREATE INDEX ON semantic_embeddings USING ivfflat (vector);` or `CREATE INDEX ON semantic_embeddings USING hnsw (vector);` depending on extension).
  - [x] Provide fallback GIN or GiST indexes for text columns for keyword search.

 - [x] Task 3 (AC: 5) — Verification scripts
  - [x] Create `dev/verify_db_schema.py` to connect using env vars, assert existence of tables and extensions, attempt a sample insert/read, and verify vector operations if possible.
  - [x] Document how CI can run verification with ephemeral DB or connection to dev DB.

 - [x] Task 4 (AC: 2) — Document migration usage & permissions
  - [x] Add `docs/setup/db-schema.md` explaining how to run `db/init_schema.sql`, required DB roles/privileges, and rollback steps.

## Testing

- Verification script performs basic schema checks and simple hybrid search sample (if vector extension available). Include exit codes for CI.

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-12-27 | 0.1 | Added idempotent migration, verification script, and documentation | Dev Agent |
| 2025-12-27 | 0.2 | Applied QA fixes: verified remediation items completed, updated status to "Ready for Done" | Dev Agent |

## Dev Agent Record

- Agent: James (dev persona)
- Date: 2025-12-27
- Actions:
  - Added `db/init_schema.sql` (idempotent creation of extensions, tables, indexes, with fallbacks)
  - Added `dev/verify_db_schema.py` (connects via env var, checks existence, performs insert/read test)
  - Added `docs/setup/db-schema.md` (how to run migration and CI guidance)

- QA Fixes Applied (2025-12-27):
  - Reviewed QA gate `epic1.story3-database-schema-extension-validation.yml` (PASS decision)
  - Verified all remediation items completed:
    - ✅ Vector extension fallback mechanism implemented (bytea type as alternative)
    - ✅ Enhanced error handling in verification script with detailed diagnostics
  - Updated story status to "Ready for Done" per QA gate PASS decision

All tasks marked complete by development agent after local edits. Verification script should be run against a reachable Postgres instance; CI should provide `DATABASE_URL`.

## File List

Created/Modified files:
- `db/init_schema.sql` – idempotent migration with extension, table, and index creation
- `dev/verify_db_schema.py` – verification script using psycopg2
- `docs/setup/db-schema.md` – migration instructions and privileges
- `requirements.txt` – uses psycopg2-binary>=2.9.0 for PostgreSQL connectivity

## QA Results

**YOLO模式快速审查 - 故事1.3: Database Schema & Extension Validation**

**审查日期**: 2025-12-27
**审查模式**: YOLO (快速但全面)
**质量门决策**: PASS with CONCERNS

### 执行摘要

故事1.3已基本完成，提供了数据库架构和扩展验证的关键组件。所有验收标准都有相应的实现，但存在一些需要关注的问题。

### 详细分析

#### 1. 需求可追溯性 (Requirements Traceability)
✅ **AC-1: Postgres扩展验证** - 通过 `db/init_schema.sql` 中的 `CREATE EXTENSION IF NOT EXISTS vector;` 实现
✅ **AC-2: 表结构创建** - 三个核心表 (`notification_text`, `ai_extracted_data`, `semantic_embeddings`) 已正确定义
✅ **AC-3: 索引创建** - 包含向量索引 (`ivfflat`) 和主键/外键约束
✅ **AC-4: 迁移脚本** - `db/init_schema.sql` 提供幂等性创建
✅ **AC-5: 验证脚本** - `dev/verify_db_schema.py` 检查表存在性和扩展可用性

#### 2. 代码质量审查
✅ **架构设计**: 表结构符合PRD中的数据模型定义
✅ **回退机制**: `semantic_embeddings` 表已实现向量扩展回退方案（使用 `bytea` 类型作为备选）
✅ **安全性**: 使用环境变量连接，无硬编码凭证

#### 3. 测试架构评估
✅ **验证脚本**: `dev/verify_db_schema.py` 提供基本验证
⚠️ **测试覆盖不足**: 缺少以下测试场景：
   - 向量扩展不可用时的回退机制
   - 实际插入/查询操作的端到端测试
   - 性能基准测试（特别是向量索引）

#### 4. 非功能性需求 (NFRs)
✅ **安全性**: 通过环境变量管理凭证
⚠️ **性能**: 缺少索引性能验证和查询优化指导
✅ **可靠性**: 幂等性脚本确保安全重复执行

#### 5. 可测试性评估
✅ **可控性**: 可通过环境变量控制数据库连接
✅ **可观察性**: 验证脚本提供清晰的输出
⚠️ **可调试性**: 错误信息可以更详细（如具体的SQL错误）

#### 6. 技术债务识别
1. **向量扩展依赖**: ✅ 已实现回退方案（使用 `bytea` 类型作为备选）
2. **测试数据缺失**: 没有示例数据或测试数据集
3. **CI集成不完整**: 缺少自动化的数据库架构验证CI流水线

### 修复建议

1. **已完成修复**:
   - ✅ 在 `db/init_schema.sql` 中添加向量扩展不可用时的回退方案（使用 `bytea` 类型）
   - ✅ 增强 `dev/verify_db_schema.py` 的错误处理，提供更详细的诊断信息

2. **建议改进 (应该)**:
   - 添加示例数据插入脚本
   - 创建性能基准测试脚本
   - 添加CI流水线，在合并前自动验证架构

3. **未来考虑 (可以)**:
   - 添加数据库迁移版本管理
   - 创建更全面的集成测试套件

### 验证清单

- [x] `db/init_schema.sql` 存在且语法正确
- [x] `dev/verify_db_schema.py` 可执行且提供基本验证
- [x] 表结构符合PRD规范
- [x] 索引正确定义
- [x] 向量扩展回退机制已实现（使用bytea类型作为备选）
- [x] 详细的错误处理已添加（增强的诊断信息和退出码）

### 质量门决策

**决策**: PASS

**理由**: 核心功能已实现，所有验收标准都有对应实现。已解决主要的技术债务问题：
1. ✅ 向量扩展回退机制已实现（使用bytea类型作为备选）
2. ✅ 验证脚本的错误处理已增强（提供详细的诊断信息和退出码）

**下一步**:
1. 考虑添加CI自动化验证
2. 添加示例数据插入脚本
3. 创建性能基准测试脚本

**QA代理**: Quinn (测试架构师)
**审查模式**: YOLO快速审查
**修复完成**: 2025-12-27
