---
title: "Story 2.2: Pydantic Schema Definition (Inc. Resolution Steps)"
epic: 2
story: 2
status: Approved
---

## Story

**As a** developer,
**I want** well-defined Pydantic schemas for data validation and serialization,
**so that** AI-extracted data is consistently structured and validated throughout the system.

## Acceptance Criteria

AC-1: Complete schema for maintenance log data
- Validation steps: Schema validates raw maintenance log data from Snowflake
- Pass condition: Schema catches invalid data types, missing required fields, and constraint violations

AC-2: Schema for AI-extracted structured data
- Validation steps: Schema validates the 5-dimensional extraction (component, fault, cause, summary, resolution_steps)
- Pass condition: All five dimensions are properly typed, resolution_steps supports both text and JSON formats

AC-3: Database model definitions
- Validation steps: SQLAlchemy models align with database schema from Epic 1
- Pass condition: Models can be used for CRUD operations without manual SQL

AC-4: API request/response schemas
- Validation steps: Schemas validate incoming API requests and format outgoing responses
- Pass condition: API endpoints return consistent JSON structures, invalid requests are rejected

AC-5: Data transformation utilities
- Validation steps: Helper functions for converting between different schema types
- Pass condition: Seamless conversion between raw data, AI-extracted data, and database models

AC-6: Comprehensive test coverage
- Validation steps: Unit tests for all schemas with edge cases
- Pass condition: 100% test coverage for schema validation logic

## 验收测量方法
- 测量方法: 为每个接受准则定义可量化的测试（例如：schema 验证 -> 通过 model_validate 对多组样本进行断言；数据库模型 -> 通过 ORM round-trip 测试）。
- 测试数据来源: 使用 `tests/fixtures/` 中的合成示例数据与边界 case；必要时使用脱敏/合成的真实样本。
- 验收阈值与度量:
  - AC-1 (维护日志 schema): 模型对 1000 条合成记录的验证通过率 >= 99%。
  - AC-2 (AI 提取 schema): 对 500 个示例 JSON（含边界情形）进行验证，结构匹配率 >= 99%。
  - AC-3 (数据库模型): ORM round-trip（create/read/update/delete）在测试 DB 上通过且无异常。
  - AC-4 (API schemas): API contract tests（请求/响应示例）全部通过。
  - AC-5 (转换工具): 转换单元测试覆盖关键转换路径，断言转换前后语义等价。
  - AC-6 (测试覆盖率): 目标覆盖率为模块级 90% 以上，关键校验逻辑 100% 测试覆盖（若团队无法达成 100%，请在 Dev Notes 注明可接受替代）。
- 验证位置: `tests/models/` 下的单元测试与 `tests/integration/` 的契约测试。

## Dev Notes

### Previous Story Insights
- Story 2.1 creates ETL pipeline for data ingestion
- Database schema defined in db/init_schema.sql
- maintenance_logs table stores raw text data
- ai_extracted_data table stores structured AI output

### Data Models
From new database schema in db/init_schema.sql:

**notification_text** (通知工单主表):
- notification_id: TEXT PRIMARY KEY (通知工单ID，来自Snowflake系统的唯一工单号)
- notification_date: TIMESTAMP WITH TIME ZONE NOT NULL (工单通知/创建日期，用于增量同步)
- notification_assigned_date: TIMESTAMP WITH TIME ZONE (工单分配日期)
- notification_closed_date: TIMESTAMP WITH TIME ZONE (工单关闭日期)
- noti_category_id: TEXT (工单类别编号)
- sys_eq_id: TEXT (设备编号)
- noti_country_id: TEXT (工单国家简称)
- sys_fl_id: TEXT (设备场地编号)
- sys_mat_id: TEXT (设备物料号)
- sys_serial_id: TEXT (设备序列号)
- notification_trendcode_l1: TEXT (工单趋势代码级别1)
- notification_trendcode_l2: TEXT (工单趋势代码级别2)
- notification_trendcode_l3: TEXT (工单趋势代码级别3)
- notification_medium_text: TEXT (工单保修短文本)
- notification_text: TEXT NOT NULL (工单维修日志长文本，AI分析的主要文本)
- created_at: TIMESTAMP WITH TIME ZONE DEFAULT now() (记录创建时间)
- updated_at: TIMESTAMP WITH TIME ZONE DEFAULT now() (记录更新时间)

**ai_extracted_data** (AI提取数据表):
- id: SERIAL PRIMARY KEY
- notification_id: TEXT NOT NULL REFERENCES notification_text(notification_id) ON DELETE CASCADE
- modules_ai: TEXT (子故障模块)
- component_ai: TEXT (故障部件)
- fault_ai: TEXT (故障描述)
- process_ai: TEXT (故障流程)
- cause_ai: TEXT (根本原因)
- resolution_ai: JSONB (解决步骤，结构化JSON)
- summary: TEXT (摘要总结)
- extracted_at: TIMESTAMP WITH TIME ZONE DEFAULT now() (AI提取时间)
- confidence_score: DECIMAL(5,4) (AI提取置信度，0.0000-1.0000)
- model_version: TEXT (使用的AI模型版本)

**semantic_embeddings** (语义嵌入表):
- notification_id: TEXT NOT NULL REFERENCES notification_text(notification_id) ON DELETE CASCADE
- source_text_ai: TEXT NOT NULL (文本原文，用于调试和验证)
- vector: vector(1536) OR vector_bytea: BYTEA (fallback) (文本向量嵌入)
- created_at: TIMESTAMP WITH TIME ZONE DEFAULT now() (向量嵌入处理时间戳)

### API Specifications
From architecture.md component architecture:
- FastAPI backend will use these schemas for request/response validation
- ETL pipeline uses schemas for data validation before database insertion
- AI service uses schemas for structured output format

### File Locations
Based on EPIC2_STARTUP_PLAN.md project structure:
- `src/models/schemas.py` - Pydantic schemas for data validation
- `src/models/entities.py` - SQLAlchemy ORM models
- `src/models/__init__.py` - Exports and type definitions
- `tests/models/test_schemas.py` - Schema validation tests
- `tests/models/test_entities.py` - Database model tests

### Testing Requirements
From architecture.md testing strategy:
- Unit tests for all Pydantic schemas
- Test database model relationships
- Test schema serialization/deserialization
- Test validation error cases

### Technical Constraints
- Python 3.12 with Pydantic v2
- SQLAlchemy 2.0+ for async support
- Type hints throughout for better IDE support
- Support for both sync and async database operations

## Tasks / Subtasks

- [ ] Task 1 (AC: 1) - Maintenance log schemas
  - [ ] Create MaintenanceLogBase schema with basic fields
  - [ ] Create MaintenanceLogCreate for new records
  - [ ] Create MaintenanceLogRead for API responses
  - [ ] Add validation for external_id uniqueness constraint

- [ ] Task 2 (AC: 2) - AI-extracted data schemas
  - [ ] Create AIExtractedDataBase with 5 dimensions
  - [ ] Define ResolutionSteps type (Union[Text, List[Dict]])
  - [ ] Create validation for required vs optional fields
  - [ ] Add custom validators for business rules

- [ ] Task 3 (AC: 3) - Database models
  - [ ] Create SQLAlchemy model for maintenance_logs
  - [ ] Create SQLAlchemy model for ai_extracted_data
  - [ ] Create SQLAlchemy model for semantic_embeddings
  - [ ] Define relationships between models

- [ ] Task 4 (AC: 4) - API schemas
  - [ ] Create request schemas for AI processing
  - [ ] Create response schemas for search results
  - [ ] Create error response schemas
  - [ ] Create pagination schemas

- [ ] Task 5 (AC: 5) - Transformation utilities
  - [ ] Create functions to convert between schema types
  - [ ] Add data cleaning/normalization helpers
  - [ ] Create serialization/deserialization methods
  - [ ] Add type conversion utilities

- [ ] Task 6 (AC: 6) - Testing
  - [ ] Write unit tests for all schemas
  - [ ] Test database model operations
  - [ ] Test API schema validation
  - [ ] Test transformation utilities
  - [ ] Achieve 100% test coverage for schema module

## Testing

### Test File Location
- `tests/models/test_schemas.py` - Pydantic schema tests
- `tests/models/test_entities.py` - SQLAlchemy model tests
- `tests/models/test_transformations.py` - Data transformation tests

### Test Standards
- Use pytest with pytest-asyncio for async tests
- Test both valid and invalid data
- Test edge cases and boundary conditions
- Use hypothesis for property-based testing (optional)

### Testing Frameworks and Patterns
- pytest fixtures for database session
- factory_boy or similar for test data generation
- parameterized tests for different validation scenarios
- snapshot testing for schema serialization

### Specific Testing Requirements
- Test Pydantic validation errors are informative
- Test database constraints are enforced
- Test round-trip serialization/deserialization
- Test performance with large datasets

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-12-27 | 1.0 | Initial story creation | Scrum Master |
