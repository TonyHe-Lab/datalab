---
title: "Story 2.2: Pydantic Schema Definition (Inc. Resolution Steps)"
epic: 2
story: 2
status: Ready for Review
---

## Story

**As a** developer,
**I want** well-defined Pydantic schemas for data validation and serialization,
**so that** AI-extracted data is consistently structured and validated throughout the system.

## Acceptance Criteria

AC-1: Complete schema for maintenance log data
- Validation steps: Schema validates raw maintenance log data from Snowflake including noti_issue_type field
- Pass condition: Schema catches invalid data types, missing required fields, and constraint violations, supports issue type classification

AC-2: Schema for AI-extracted structured data
- Validation steps: Schema validates the multi-dimensional extraction including consideration of issue type relationships
- Pass condition: All dimensions are properly typed, resolution_ai supports both text and JSON formats, supports issue type analysis dimension

AC-3: Database model definitions
- Validation steps: SQLAlchemy models align with database schema from Epic 1
- Pass condition: Models can be used for CRUD operations without manual SQL

AC-4: API request/response schemas
- Validation steps: Schemas validate incoming API requests and format outgoing responses
- Pass condition: API endpoints return consistent JSON structures, invalid requests are rejected

AC-5: Data transformation utilities
- Validation steps: Helper functions for converting between different schema types
- Pass condition: Seamless conversion between raw data, AI-extracted data, and database models

AC-6: Comprehensive test coverage
- Validation steps: Unit tests for all schemas with edge cases
- Pass condition: 100% test coverage for schema validation logic

## 验收测量方法
- 测量方法: 为每个接受准则定义可量化的测试（例如：schema 验证 -> 通过 model_validate 对多组样本进行断言；数据库模型 -> 通过 ORM round-trip 测试）。
- 测试数据来源: 使用 `tests/fixtures/` 中的合成示例数据与边界 case；必要时使用脱敏/合成的真实样本。
- 验收阈值与度量:
  - AC-1 (维护日志 schema): 模型对 1000 条合成记录的验证通过率 >= 99%。
  - AC-2 (AI 提取 schema): 对 500 个示例 JSON（含边界情形）进行验证，结构匹配率 >= 99%。
  - AC-3 (数据库模型): ORM round-trip（create/read/update/delete）在测试 DB 上通过且无异常。
  - AC-4 (API schemas): API contract tests（请求/响应示例）全部通过。
  - AC-5 (转换工具): 转换单元测试覆盖关键转换路径，断言转换前后语义等价。
  - AC-6 (测试覆盖率): 目标覆盖率为模块级 90% 以上，关键校验逻辑 100% 测试覆盖（若团队无法达成 100%，请在 Dev Notes 注明可接受替代）。
- 验证位置: `tests/models/` 下的单元测试与 `tests/integration/` 的契约测试。

## Dev Notes

### Previous Story Insights
- Story 2.1 creates ETL pipeline for data ingestion
- Database schema defined in db/init_schema.sql
- notification_text table stores raw text data with standardized field naming (noti_ prefix)
- ai_extracted_data table stores structured AI output
- **字段命名规范**: 所有工单相关字段使用`noti_`前缀，设备相关字段使用`sys_`前缀

### Data Models
From new database schema in db/init_schema.sql:

**notification_text** (通知工单主表):
- notification_id: TEXT PRIMARY KEY (通知工单ID，来自Snowflake系统的唯一工单号)
- noti_date: TIMESTAMP WITH TIME ZONE NOT NULL (工单通知/创建日期，用于增量同步)
- noti_assigned_date: TIMESTAMP WITH TIME ZONE (工单分配日期)
- noti_closed_date: TIMESTAMP WITH TIME ZONE (工单关闭日期)
- noti_category_id: TEXT (工单类别编号)
- sys_eq_id: TEXT (设备编号)
- noti_country_id: TEXT (工单国家简称)
- sys_fl_id: TEXT (设备场地编号)
- sys_mat_id: TEXT (设备物料号)
- sys_serial_id: TEXT (设备序列号)
- noti_trendcode_l1: TEXT (工单趋势代码级别1)
- noti_trendcode_l2: TEXT (工单趋势代码级别2)
- noti_trendcode_l3: TEXT (工单趋势代码级别3)
- noti_issue_type: TEXT (工单问题类型，如：硬件故障、软件问题等)
- noti_medium_text: TEXT (工单保修短文本)
- noti_text: TEXT NOT NULL (工单维修日志长文本，AI分析的主要文本)
- created_at: TIMESTAMP WITH TIME ZONE DEFAULT now() (记录创建时间)
- updated_at: TIMESTAMP WITH TIME ZONE DEFAULT now() (记录更新时间)

**ai_extracted_data** (AI提取数据表):
- id: SERIAL PRIMARY KEY
- notification_id: TEXT NOT NULL REFERENCES notification_text(notification_id) ON DELETE CASCADE
- modules_ai: TEXT (子故障模块)
- component_ai: TEXT (故障部件)
- fault_ai: TEXT (故障描述)
- process_ai: TEXT (故障流程)
- cause_ai: TEXT (根本原因)
- resolution_ai: JSONB (解决步骤，结构化JSON)
- summary: TEXT (摘要总结)
- extracted_at: TIMESTAMP WITH TIME ZONE DEFAULT now() (AI提取时间)
- confidence_score: DECIMAL(5,4) (AI提取置信度，0.0000-1.0000)
- model_version: TEXT (使用的AI模型版本)

**semantic_embeddings** (语义嵌入表):
- notification_id: TEXT NOT NULL REFERENCES notification_text(notification_id) ON DELETE CASCADE
- source_text_ai: TEXT NOT NULL (文本原文，用于调试和验证)
- vector: vector(1536) OR vector_bytea: BYTEA (fallback) (文本向量嵌入)
- created_at: TIMESTAMP WITH TIME ZONE DEFAULT now() (向量嵌入处理时间戳)

### API Specifications
From architecture.md component architecture:
- FastAPI backend will use these schemas for request/response validation
- ETL pipeline uses schemas for data validation before database insertion
- AI service uses schemas for structured output format

### File Locations
Based on EPIC2_STARTUP_PLAN.md project structure:
- `src/models/schemas.py` - Pydantic schemas for data validation
- `src/models/entities.py` - SQLAlchemy ORM models
- `src/models/__init__.py` - Exports and type definitions
- `tests/models/test_schemas.py` - Schema validation tests
- `tests/models/test_entities.py` - Database model tests

### Testing Requirements
From architecture.md testing strategy:
- Unit tests for all Pydantic schemas
- Test database model relationships
- Test schema serialization/deserialization
- Test validation error cases

### Technical Constraints
- Python 3.12 with Pydantic v2
- SQLAlchemy 2.0+ for async support
- Type hints throughout for better IDE support
- Support for both sync and async database operations

## Tasks / Subtasks

- [x] Task 1 (AC: 1) - Maintenance log schemas
  - [x] Create MaintenanceLogBase schema with basic fields
  - [x] Create MaintenanceLogCreate for new records
  - [x] Create MaintenanceLogRead for API responses
  - [x] Add validation for external_id uniqueness constraint

- [x] Task 2 (AC: 2) - AI-extracted data schemas
  - [x] Create AIExtractedDataBase with 5 dimensions
  - [x] Define ResolutionSteps type (Union[Text, List[Dict]])
  - [x] Create validation for required vs optional fields
  - [x] Add custom validators for business rules

- [x] Task 3 (AC: 3) - Database models
  - [x] Create SQLAlchemy model for notification_text
  - [x] Create SQLAlchemy model for ai_extracted_data
  - [x] Create SQLAlchemy model for semantic_embeddings
  - [x] Define relationships between models

- [x] Task 4 (AC: 4) - API schemas
  - [x] Create request schemas for AI processing
  - [x] Create response schemas for search results
  - [x] Create error response schemas
  - [x] Create pagination schemas

- [x] Task 5 (AC: 5) - Transformation utilities
  - [x] Create functions to convert between schema types
  - [x] Add data cleaning/normalization helpers
  - [x] Create serialization/deserialization methods
  - [x] Add type conversion utilities

- [x] Task 6 (AC: 6) - Testing
  - [x] Write unit tests for all schemas
  - [x] Test database model operations
  - [x] Test API schema validation
  - [x] Test transformation utilities
  - [x] Achieve 100% test coverage for schema module

## Testing

### Test File Location
- `tests/models/test_schemas.py` - Pydantic schema tests
- `tests/models/test_entities.py` - SQLAlchemy model tests
- `tests/models/test_transformations.py` - Data transformation tests

### Test Standards
- Use pytest with pytest-asyncio for async tests
- Test both valid and invalid data
- Test edge cases and boundary conditions
- Use hypothesis for property-based testing (optional)

### Testing Frameworks and Patterns
- pytest fixtures for database session
- factory_boy or similar for test data generation
- parameterized tests for different validation scenarios
- snapshot testing for schema serialization

### Specific Testing Requirements
- Test Pydantic validation errors are informative
- Test database constraints are enforced
- Test round-trip serialization/deserialization
- Test performance with large datasets

## Dev Agent Record

### Agent Model Used
- James (Developer Agent)

### Debug Log References
- All tests passing: schemas, entities, transformations
- Fixed SQLite/PostgreSQL compatibility issues
- Updated requirements.txt with SQLAlchemy dependencies

### Completion Notes List
1. ✅ Created comprehensive Pydantic schemas for all data types
2. ✅ Implemented SQLAlchemy ORM models matching database schema
3. ✅ Built transformation utilities for schema-ORM conversions
4. ✅ Added data normalization and cleaning functions
5. ✅ Implemented API request/response schemas
6. ✅ Created comprehensive test suite with 100% coverage for schema module
7. ✅ Fixed field mappings between schemas and database (resolution_steps not in DB)
8. ✅ Handled JSON vs TEXT field conversions for database compatibility

### File List
**Created Files:**
- `src/models/schemas.py` - Pydantic schemas for data validation
- `src/models/entities.py` - SQLAlchemy ORM models
- `src/models/__init__.py` - Package exports and type definitions
- `src/models/transformations/__init__.py` - Data transformation utilities
- `tests/models/test_schemas.py` - Schema validation tests (28 tests)
- `tests/models/test_entities.py` - Database model tests (20 tests)
- `tests/models/test_transformations.py` - Transformation utility tests (30 tests)

**Modified Files:**
- `requirements.txt` - Added SQLAlchemy, Alembic, pytest-asyncio dependencies
- `docs/stories/2.2.Pydantic-Schema-Definition.md` - Updated task status and added Dev Agent Record

### Change Log
| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-12-27 | 1.0 | Initial story creation | Scrum Master |
| 2025-12-28 | 1.1 | Complete implementation of all schemas, models, transformations and tests | James (Dev Agent) |
