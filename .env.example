# .env.example
# Environment variables template for datalab project
# Copy this file to `.env` and fill in your actual values
# NEVER commit `.env` to version control (it's in .gitignore)

# --- Database Connection ---
# Option 1: Use a full connection string (preferred)
DATABASE_URL="postgresql://postgres:password@localhost:5432/datalab"
# Alternative: separate components (used by some scripts)
POSTGRES_HOST="localhost"
POSTGRES_PORT="5432"
POSTGRES_USER="postgres"
POSTGRES_PASSWORD="password"
POSTGRES_DB="datalab"

# --- Snowflake Connection (for ETL) ---
# Required for Story 2.1: Incremental ETL from Snowflake to Postgres
SNOWFLAKE_ACCOUNT="your-account.snowflakecomputing.com"
SNOWFLAKE_USER="your-username"
SNOWFLAKE_PASSWORD="your-password"  # Optional if using SSO
SNOWFLAKE_AUTHENTICATOR="snowflake"  # Options: 'snowflake' (default), 'externalbrowser' (SSO), 'oauth'
SNOWFLAKE_WAREHOUSE="your-warehouse"
SNOWFLAKE_DATABASE="your-database"
SNOWFLAKE_SCHEMA="your-schema"
SNOWFLAKE_ROLE="your-role"  # Optional

# --- AI/OpenAI Integration (for future stories) ---
# Required for AI extraction and embedding generation
OPENAI_API_KEY="your-openai-api-key-here"
OPENAI_END_POINT="https://api.openai.com/v1"
# Optional: model selection
OPENAI_MODEL="gpt-4o-mini"
EMBEDDING_MODEL="text-embedding-3-small"

# --- Backend Service Configuration ---
API_HOST="0.0.0.0"
API_PORT="8000"
LOG_LEVEL="info"

# --- Frontend Configuration (if needed) ---
VITE_API_BASE_URL="http://localhost:8000"

# --- ETL Configuration ---
ETL_BATCH_SIZE="1000"
ETL_MAX_RETRIES="3"
ETL_RETRY_DELAY="5"